import torch
from torch import nn
import torch.cuda.amp as amp
import torchvision
from torchvision import transforms as T, models
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
from torchmetrics import Accuracy
from tqdm import tqdm
import multiprocessing

def main():
    multiprocessing.freeze_support()

    print("設定資料轉換...")
    data_transform = T.Compose([
        T.Resize(256), T.CenterCrop(224),
        T.ToTensor(), T.Normalize(mean=[0.5]*3, std=[0.5]*3)
    ])
    from torchvision.datasets import CIFAR10
    train_data = CIFAR10(root='./data', train=True,  download=True, transform=data_transform)
    test_data  = CIFAR10(root='./data', train=False, download=True, transform=data_transform)
    num_classes = len(train_data.class_to_idx)

    print("資料集資訊:")
    print(f"測試資料形狀: {test_data[0][0].shape}")
    print(f"訓練資料類別對應: {train_data.class_to_idx}")

    print("建立資料載入器...")
    train_loader = DataLoader(train_data, batch_size=128, shuffle=True,
                              num_workers=4, pin_memory=True)
    test_loader  = DataLoader(test_data,  batch_size=128, shuffle=False,
                              num_workers=4, pin_memory=True)

    # 示範一個 batch
    x, y = next(iter(train_loader))
    print(f"批次資料形狀: {x.shape}, {y.shape}")
    plt.imshow((x[0]*0.5+0.5).permute(1,2,0))

    print("初始化模型...")
    # 若你的 torchvision 版本沒有這個屬性，可先 upgrade 或 fallback
    try:
        model = models.vit_b_16()
    except AttributeError:
        from torchvision.models.vision_transformer import vit_tiny_patch16_224
        model = models.ViT_B_16_Weights()
    in_features = model.heads[0].in_features
    model.heads = nn.Linear(in_features, num_classes)

    print("設定優化器和損失函數...")
    optimizer = torch.optim.SGD(model.parameters(), lr=0.05,
                                momentum=0.9, nesterov=True,
                                weight_decay=1e-4)
    loss_fn = nn.CrossEntropyLoss()

    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"使用設備: {device}")
    model.to(device)
    scaler = amp.GradScaler()

    class AverageMeter(object) :
        def __init__(self):
            self.reset()
        def reset(self) :
            self.avg = 0
            self.val = 0
            self.sum = 0
            self.count = 0
        def update (self, val, n=1) :
            self.val = val
            self.count += n
            self.sum += self.val * n
            self.avg = self.sum / self.count

    def train(model, train_loader, optimizer, loss_fn, epoch=None):
        model.train()
        train_loss = AverageMeter()
        train_acc = Accuracy(task='multiclass', num_classes=num_classes).to(device)
        with tqdm(train_loader, unit='batch') as tepoch:
            for inputs, targets in tepoch:
                tepoch.set_description(f'Epoch {epoch}' if epoch is not None else '')
                inputs, targets = inputs.to(device), targets.to(device)

                optimizer.zero_grad()
                with amp.autocast():   # 自動混合精度
                    outputs = model(inputs)
                    loss    = loss_fn(outputs, targets)

                scaler.scale(loss).backward()
                scaler.step(optimizer)
                scaler.update()

                train_loss.update(loss.item())
                train_acc(outputs.argmax(1), targets)
                tepoch.set_postfix(loss=train_loss.avg,
                                accuracy=100*train_acc.compute().item())
        return model, train_loss.avg, train_acc.compute()

    def evaluate(model, test_loader, loss_fn):
        model.eval()
        test_loss = AverageMeter()
        test_acc = Accuracy(task='multiclass', num_classes=num_classes).to(device)
        with torch.no_grad(), tqdm(test_loader, unit='batch') as tepoch:
            for inputs, targets in tepoch:
                inputs, targets = inputs.to(device), targets.to(device)
                with amp.autocast():   # 自動混合精度
                    outputs = model(inputs)
                    loss = loss_fn(outputs, targets)

                test_loss.update(loss.item())
                test_acc(outputs.argmax(dim=1), targets)
                tepoch.set_postfix(loss=test_loss.avg,
                                accuracy=100*test_acc.compute().item())
        return test_loss.avg, test_acc.compute()

    loss_train_hist = []
    loss_valid_hist = []
    acc_train_hist = []
    acc_valid_hist = []

    num_epochs = 200
    for epoch in range(num_epochs):
        model, train_loss, train_acc = train(model, train_loader, optimizer, loss_fn, epoch)

        test_loss, test_acc = evaluate(model, test_loader, loss_fn)
        loss_train_hist.append(train_loss)
        loss_valid_hist.append(test_loss if isinstance(test_loss, float) else test_loss.to('cpu'))

        acc_train_hist.append(train_acc if isinstance(train_acc, float) else train_acc.to('cpu'))
        acc_valid_hist.append(test_acc if isinstance(test_acc, float) else test_acc.to('cpu'))
        print(f'Test - Loss:{test_loss} - Accuracy:{test_acc}')
        print()
        print()

    # 儲存最終訓練好的模型
    torch.save({
        'model_state': model.state_dict(),
        'optimizer_state': optimizer.state_dict(),
        'epochs': num_epochs
    }, 'vit_tiny_cifar10_{}.pt'.format(device))
    print("模型已儲存為 vit_tiny_cifar10_{}.pt".format(device))

    #plot
    plt.plot(range(num_epochs), loss_train_hist, 'k-', label="Train")
    plt.plot(range(num_epochs), loss_valid_hist, 'y-', label="Validation")
    plt.xlabel('Epoch'); plt.ylabel('Loss')
    plt.legend(); plt.grid(True)

    plt.figure()
    plt.plot(range(num_epochs), acc_train_hist, 'k-', label='Train')
    plt.plot(range(num_epochs), acc_valid_hist, 'm-', label='Validation')
    plt.xlabel('Epoch'); plt.ylabel('Accuracy')
    plt.legend(); plt.grid(True)

    plt.show()

if __name__ == "__main__":
    main()